{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from typing import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image_folder, label_folder, output_json):\n",
    "    \"\"\"Procesa todas las imágenes en la carpeta y extrae características de cada espora.\"\"\"\n",
    "    all_features = {}\n",
    "\n",
    "    # Obtener lista de archivos en ambas carpetas\n",
    "    image_files = {os.path.splitext(f)[0]: os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    label_files = {os.path.splitext(f)[0]: os.path.join(label_folder, f) for f in os.listdir(label_folder) if f.endswith('.txt')}\n",
    "\n",
    "    # Procesar solo los archivos que tienen imagen y label correspondiente\n",
    "    common_files = image_files.keys() & label_files.keys()\n",
    "\n",
    "    # Cargar el archivo YAML\n",
    "    try:\n",
    "        with open(\".\\\\Imagenes\\\\dataset\\\\data.yaml\", \"r\") as file:\n",
    "            data = yaml.safe_load(file)  # Carga el contenido del YAML\n",
    "    except:\n",
    "        with open(\"../Imagenes/dataset/data.yaml\", \"r\") as file:\n",
    "            data = yaml.safe_load(file)  # Carga el contenido del YAML\n",
    "\n",
    "    # Extraer la lista de nombres de las clases\n",
    "    class_names = data.get(\"names\", [])  # Si \"names\" no existe, devuelve una lista vacía\n",
    "\n",
    "    for file_name in tqdm(common_files):\n",
    "        image_path = image_files[file_name]\n",
    "        label_path = label_files[file_name]\n",
    "\n",
    "        # print(f\"Procesando: {image_path} con {label_path}\")\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen {image_path}\")\n",
    "            continue\n",
    "\n",
    "        bboxes = load_labels(label_path, image.shape)\n",
    "\n",
    "        for i, (class_id, x_min, y_min, width, height) in enumerate(bboxes):\n",
    "            roi = image[y_min:y_min+height, x_min:x_min+width]\n",
    "\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            features = extract_features(roi)\n",
    "            # Agregar información del bounding box\n",
    "            espora_id = f\"{file_name}_espora_{i}_class_{class_id}\"\n",
    "            all_features[espora_id] = {\n",
    "                \"bounding_box\": {\n",
    "                    \"class\": class_names[class_id],\n",
    "                    \"x_min\": x_min,\n",
    "                    \"y_min\": y_min,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height\n",
    "                },\n",
    "                \"features\": features\n",
    "            }\n",
    "\n",
    "    # Guardar en JSON\n",
    "    with open(output_json, \"w\") as json_file:\n",
    "        json.dump(all_features, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_database(json_path):\n",
    "    \"\"\"Carga la base de datos de esporas desde un JSON.\"\"\"\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except:\n",
    "        try:\n",
    "            image_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\images\"\n",
    "            label_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\labels\"\n",
    "            output_json = \".\\\\spore_features.json\"\n",
    "        except:\n",
    "            image_folder = \"../Imágenes/dataset/train/images\"\n",
    "            label_folder = \"../Imágenes/dataset/train/labels\"\n",
    "            output_json = \"../spore_features.json\"\n",
    "        process_images(image_folder, label_folder, output_json)\n",
    "\n",
    "\n",
    "# Cargar base de datos\n",
    "try:\n",
    "    database = load_database(\"D:\\\\MatCom\\\\4toanno\\\\1er_Semestre\\\\Machine_Learning\\\\Proyecto\\\\CBR_algorithim\\\\spore_features.json\")\n",
    "except:\n",
    "    database = load_database(\"../spore_features.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chi_square_distance(hist1, hist2):\n",
    "    \"\"\"Calcula la distancia Chi-cuadrado entre dos histogramas.\"\"\"\n",
    "    return 0.5 * np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-7))\n",
    "\n",
    "def compare_cases(case1, case2):\n",
    "    \"\"\"Calcula la similitud entre dos esporas usando varias métricas.\"\"\"\n",
    "    \n",
    "    # Comparación de bounding box (penaliza esporas con tamaños muy diferentes)\n",
    "    bbox_diff = abs(case1[\"bounding_box\"][\"width\"] - case2[\"bounding_box\"][\"width\"]) + \\\n",
    "                abs(case1[\"bounding_box\"][\"height\"] - case2[\"bounding_box\"][\"height\"])\n",
    "\n",
    "    # Comparación de estadísticas básicas (media, desviación estándar, valores mínimo y máximo)\n",
    "    stats1 = np.array([case1[\"features\"][\"stats\"][\"mean_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"std_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"min_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"max_gray\"]])\n",
    "    stats2 = np.array([case2[\"features\"][\"stats\"][\"mean_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"std_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"min_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"max_gray\"]])\n",
    "    stats_distance = euclidean(stats1, stats2)\n",
    "\n",
    "    # Comparación de histogramas de color en HSV\n",
    "    hist1 = np.concatenate(case1[\"features\"][\"color_features\"][\"hist_hsv\"])\n",
    "    hist2 = np.concatenate(case2[\"features\"][\"color_features\"][\"hist_hsv\"])\n",
    "    hist_similarity = cosine(hist1, hist2)\n",
    "\n",
    "    # Comparación de características de textura (GLCM)\n",
    "    texture1 = np.array([\n",
    "        case1[\"features\"][\"texture_features\"][\"contrast\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"homogeneity\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"energy\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"correlation\"]\n",
    "    ])\n",
    "    texture2 = np.array([\n",
    "        case2[\"features\"][\"texture_features\"][\"contrast\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"homogeneity\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"energy\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"correlation\"]\n",
    "    ])\n",
    "    texture_distance = euclidean(texture1, texture2)\n",
    "\n",
    "    # Comparación de momentos de Hu (medida de similitud basada en distancia euclidiana)\n",
    "    hu1 = np.array(case1[\"features\"][\"stats\"][\"hu_moments\"])\n",
    "    hu2 = np.array(case2[\"features\"][\"stats\"][\"hu_moments\"])\n",
    "    hu_distance = euclidean(hu1, hu2)\n",
    "\n",
    "    # Comparación de LBP (usando distancia de Chi-cuadrado)\n",
    "    lbp1 = np.array(case1[\"features\"][\"texture_features\"][\"lbp_histogram\"])\n",
    "    lbp2 = np.array(case2[\"features\"][\"texture_features\"][\"lbp_histogram\"])\n",
    "    lbp_distance = chi_square_distance(lbp1, lbp2)\n",
    "\n",
    "    # Ponderación de las similitudes\n",
    "    similarity_score = (stats_distance * 0.2) + (hist_similarity * 0.25) + \\\n",
    "                       (texture_distance * 0.2) + (hu_distance * 0.2) + \\\n",
    "                       (lbp_distance * 0.1) + (bbox_diff * 0.05)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "def find_similar_cases(new_case, database, top_n=5):\n",
    "    \"\"\"Encuentra los casos más similares en la base de datos.\"\"\"\n",
    "    similarities = []\n",
    "\n",
    "    for espora_id, case in database.items():\n",
    "        score = compare_cases(new_case, case)\n",
    "        similarities.append((database[espora_id][\"bounding_box\"][\"class\"], score))\n",
    "\n",
    "    # Ordenar por menor distancia (más similar)\n",
    "    similarities.sort(key=lambda x: x[1])\n",
    "\n",
    "    k_values = similarities[:top_n]\n",
    "    threshold = 70\n",
    "\n",
    "    # Decisión basada en umbral\n",
    "    if min(k_values)[1] > threshold:\n",
    "        return \"Clasificación manual requerida\"\n",
    "    else:\n",
    "        most_common = Counter(k_values).most_common()\n",
    "        return most_common\n",
    "    \n",
    "def calculate_dynamic_threshold(database):\n",
    "    \"\"\"Calcula un umbral basado en el percentil 90 de las similitudes previas.\"\"\"\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i in range(len(database)):\n",
    "        for j in range(i + 1, len(database)):\n",
    "            similarity_scores.append(compare_cases(database[i], database[j]))\n",
    "\n",
    "    return float(np.percentile(similarity_scores, 90))  # Usa el percentil 90 como umbral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path, image_shape):\n",
    "    \"\"\"Carga los bounding boxes desde un archivo de etiquetas YOLO.\"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    bboxes = []\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = line.strip().split()\n",
    "        class_id = int(values[0])\n",
    "        x_center, y_center, width, height = map(float, values[1:])\n",
    "\n",
    "        # Convertir coordenadas normalizadas a píxeles\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        box_width = int(width * w)\n",
    "        box_height = int(height * h)\n",
    "\n",
    "        bboxes.append((class_id, x_min, y_min, box_width, box_height))\n",
    "\n",
    "    return bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    \"\"\"Extrae características de color, textura y estadísticas de una imagen.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Estadísticas básicas\n",
    "    mean_gray =float(np.mean(gray))\n",
    "    std_gray = float(np.std(gray))\n",
    "    min_gray = float(np.min(gray))\n",
    "    max_gray = float(np.max(gray))\n",
    "\n",
    "    # Características de forma (Momentos de Hu)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = list(cv2.HuMoments(moments).flatten())\n",
    "\n",
    "    # Características de color (media y desviación estándar en RGB)\n",
    "    mean_rgb = list(np.mean(image, axis=(0, 1)).tolist())\n",
    "    std_rgb = list(np.std(image, axis=(0, 1)).tolist())\n",
    "\n",
    "    # Características de color (media y desviación estándar en HSV)\n",
    "    mean_hsv = list(np.mean(hsv, axis=(0, 1)).tolist())\n",
    "    std_hsv = list(np.std(hsv, axis=(0, 1)).tolist())\n",
    "\n",
    "    # Histograma de color en RGB\n",
    "    list_rgb = [cv2.calcHist([image], [i], None, [256], [0, 256]).flatten().tolist() for i in range(3)]\n",
    "    hist_rgb = [list([float(n) for n in h]) for h in list_rgb] # Cantidad de píxeles para cada posible intensidad de color (de 0 a 255).\n",
    "\n",
    "    # Histograma de color en HSV (normalizado)\n",
    "    list_hsv = [cv2.calcHist([hsv], [i], None, [256], [0, 256]).flatten() for i in range(3)]\n",
    "    hist_hsv = [h / h.sum() for h in list_hsv]  # Normalización\n",
    "\n",
    "    # Textura: características GLCM\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "\n",
    "    # Local Binary Pattern (LBP)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    lbp_hist = lbp_hist.astype(\"float\")\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-7)  # Normalización\n",
    "\n",
    "    return {\n",
    "        \"color_features\": {\n",
    "            \"mean_hsv\": mean_hsv,\n",
    "            \"std_hsv\": std_hsv,\n",
    "            \"hist_hsv\": [h.tolist() for h in hist_hsv]  # Convertir a lista para JSON\n",
    "        },\n",
    "        \"texture_features\": {\n",
    "            \"contrast\": contrast,\n",
    "            \"dissimilarity\": dissimilarity,\n",
    "            \"homogeneity\": homogeneity,\n",
    "            \"energy\": energy,\n",
    "            \"correlation\": correlation,\n",
    "            \"lbp_histogram\": lbp_hist.tolist()\n",
    "        },\n",
    "        \"stats\": {\n",
    "            \"mean_gray\": mean_gray,\n",
    "            \"std_gray\": std_gray,\n",
    "            \"min_gray\": min_gray,\n",
    "            \"max_gray\": max_gray,\n",
    "            \"hu_moments\": hu_moments\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image):\n",
    "    \"\"\" Segmenta la imagen para detectar esporas. \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "\n",
    "    return bounding_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image,case_database):\n",
    "    \"\"\" Predice el tipo de espora en una imagen usando CBR y aprendizaje automático. \"\"\"\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # 1. Segmentar la imagen\n",
    "    bounding_boxes = segment_image(image)\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        # 2. Extraer características de la espora detectada\n",
    "        x, y, w, h = box\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        features = extract_features(roi)\n",
    "        all_features = {\n",
    "                \"bounding_box\": {\n",
    "                    \"class\": '',\n",
    "                    \"x_min\": x,\n",
    "                    \"y_min\": y,\n",
    "                    \"width\": w,\n",
    "                    \"height\": h\n",
    "                },\n",
    "                \"features\": features\n",
    "            }\n",
    "\n",
    "        # 3. Buscar el caso más similar en la base de datos\n",
    "        best_case = find_similar_cases(all_features, case_database)\n",
    "\n",
    "      \n",
    "\n",
    "    return best_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MatCom\\4toanno\\1er_Semestre\\Machine_Learning\\Proyecto\\CBR_algorithim\\Imagenes\\dataset\\valid\\images\\11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/117 [00:01<03:29,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espora detectada en 11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d - Tipo: ('curvularia', 63.79278384792397) \n",
      "Espora detectada en 11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d - Tipo: ('curvularia', 64.67759677076519) \n",
      "Espora detectada en 11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d - Tipo: ('curvularia', 65.43183872282592) \n",
      "Espora detectada en 11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d - Tipo: ('curvularia', 65.65708644479831) \n",
      "Espora detectada en 11_1_jpg.rf.6d62d45ffe0decd5483c40ae58cbb24d - Tipo: ('curvularia', 65.96328161824286) \n",
      "D:\\MatCom\\4toanno\\1er_Semestre\\Machine_Learning\\Proyecto\\CBR_algorithim\\Imagenes\\dataset\\valid\\images\\11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/117 [00:04<04:08,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espora detectada en 11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3 - Tipo: ('curvularia', 64.71380421119741) \n",
      "Espora detectada en 11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3 - Tipo: ('curvularia', 65.81168646765775) \n",
      "Espora detectada en 11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3 - Tipo: ('curvularia', 66.66485877371353) \n",
      "Espora detectada en 11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3 - Tipo: ('curvularia', 66.85564706075618) \n",
      "Espora detectada en 11_3_jpg.rf.449adc22ccdf26ad94b98e004d1be7f3 - Tipo: ('curvularia', 67.54128923264929) \n",
      "D:\\MatCom\\4toanno\\1er_Semestre\\Machine_Learning\\Proyecto\\CBR_algorithim\\Imagenes\\dataset\\valid\\images\\16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/117 [00:07<04:48,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espora detectada en 16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7 - Tipo: ('curvularia', 66.10185762416332) \n",
      "Espora detectada en 16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7 - Tipo: ('curvularia', 66.3695242992501) \n",
      "Espora detectada en 16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7 - Tipo: ('cladosporium', 66.51341219683913) \n",
      "Espora detectada en 16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7 - Tipo: ('cladosporium', 67.00494560780588) \n",
      "Espora detectada en 16_1_jpg.rf.1a7bd56ac1473510d3016f1a102879d7 - Tipo: ('curvularia', 67.05115875186107) \n",
      "D:\\MatCom\\4toanno\\1er_Semestre\\Machine_Learning\\Proyecto\\CBR_algorithim\\Imagenes\\dataset\\valid\\images\\16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/117 [00:09<04:16,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espora detectada en 16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5 - Tipo: ('curvularia', 62.33747228022654) \n",
      "Espora detectada en 16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5 - Tipo: ('curvularia', 62.900643982487026) \n",
      "Espora detectada en 16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5 - Tipo: ('curvularia', 63.65332287406624) \n",
      "Espora detectada en 16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5 - Tipo: ('curvularia', 64.18875514361713) \n",
      "Espora detectada en 16_1_jpg.rf.c7bbcb931ed3ff67a07ca176de5063d5 - Tipo: ('curvularia', 64.79043879632961) \n",
      "D:\\MatCom\\4toanno\\1er_Semestre\\Machine_Learning\\Proyecto\\CBR_algorithim\\Imagenes\\dataset\\valid\\images\\18_2_jpg.rf.9da0ae887c5930a714093651e5f97bd8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/117 [00:10<04:49,  2.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(valid_image_files[image])\n\u001b[0;32m     25\u001b[0m     image1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(valid_image_files[image])\n\u001b[1;32m---> 26\u001b[0m     resultados \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#     # Mostrar resultados\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m resultados:\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image, case_database)\u001b[0m\n\u001b[0;32m     11\u001b[0m x, y, w, h \u001b[38;5;241m=\u001b[39m box\n\u001b[0;32m     12\u001b[0m roi \u001b[38;5;241m=\u001b[39m image[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[1;32m---> 13\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m all_features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: features\n\u001b[0;32m     23\u001b[0m     }\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 3. Buscar el caso más similar en la base de datos\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     38\u001b[0m correlation \u001b[38;5;241m=\u001b[39m graycoprops(glcm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Local Binary Pattern (LBP)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m lbp \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_binary_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m lbp_hist, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(lbp\u001b[38;5;241m.\u001b[39mravel(), bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m11\u001b[39m), \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     43\u001b[0m lbp_hist \u001b[38;5;241m=\u001b[39m lbp_hist\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\feature\\texture.py:367\u001b[0m, in \u001b[0;36mlocal_binary_pattern\u001b[1;34m(image, P, R, method)\u001b[0m\n\u001b[0;32m    360\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying `local_binary_pattern` to floating-point images may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive unexpected results when small numerical differences between \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjacent pixels are present. It is recommended to use this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction with images of integer dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m     )\n\u001b[0;32m    366\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(image, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m--> 367\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_local_binary_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     image_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\images\"\n",
    "#     label_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\labels\"\n",
    "#     output_json = \".\\\\spore_features.json\"\n",
    "# except:\n",
    "#     image_folder = \"../Imágenes/dataset/train/images\"\n",
    "#     label_folder = \"../Imágenes/dataset/train/labels\"\n",
    "#     output_json = \"../spore_features.json\"\n",
    "# process_images(image_folder, label_folder, output_json)\n",
    "\n",
    "\n",
    "\n",
    "# Cargar imagen\n",
    "try:\n",
    "    valid_image_folder = \"D:\\\\MatCom\\\\4toanno\\\\1er_Semestre\\\\Machine_Learning\\\\Proyecto\\\\CBR_algorithim\\\\Imagenes\\\\dataset\\\\valid\\\\images\"\n",
    "    valid_image_files = {os.path.splitext(f)[0]: os.path.join(valid_image_folder, f) for f in os.listdir(valid_image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "except:\n",
    "    valid_image_folder = \"../Imágenes/dataset/valid/images\"\n",
    "    valid_image_files = {os.path.splitext(f)[0]: os.path.join(valid_image_folder, f) for f in os.listdir(valid_image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "\n",
    "\n",
    "# # Ejecutar predicción\n",
    "for image in tqdm(valid_image_files.keys()):\n",
    "    print(valid_image_files[image])\n",
    "    image1 = cv2.imread(valid_image_files[image])\n",
    "    resultados = predict(image1, database)\n",
    "\n",
    "#     # Mostrar resultados\n",
    "    for res in resultados:\n",
    "        print(f\"Espora detectada en {image} - Tipo: {res[0]} \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
